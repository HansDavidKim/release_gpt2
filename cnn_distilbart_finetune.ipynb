{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file must be run on Colab with T4 GPU\n",
    "Dataset : CNN Daily/Mail 3.0.0\n",
    "\n",
    "Model : DistilBart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade fsspec datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 설치:\n",
    "# pip install transformers datasets safetensors torch tqdm\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# 1. 설정\n",
    "model_name  = \"sshleifer/distilbart-cnn-6-6\"\n",
    "cache_dir   = \"./hf_cache\"                   # 데이터셋·모델 캐시\n",
    "save_dir    = \"./distilbart_cnn_safetensors\" # 최종 저장 경로\n",
    "batch_size  = 2                              # 메모리에 따라 조정\n",
    "num_epochs  = 1\n",
    "max_samples = 2048                           # 전체 샘플 중 사용할 개수\n",
    "\n",
    "# 2. 토크나이저·모델 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# 3. 데이터셋 로드 및 샘플 선택\n",
    "raw_ds  = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\", cache_dir=cache_dir)\n",
    "dataset = raw_ds.select(range(max_samples))\n",
    "\n",
    "# 4. 전처리 함수: encoder-decoder 구조이므로 \"summarize:\" 프롬프트 불필요\n",
    "def preprocess(ex):\n",
    "    enc = tokenizer(\n",
    "        ex[\"article\"],\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    lbl = tokenizer(\n",
    "        ex[\"highlights\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\":      enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"],\n",
    "        \"labels\":         lbl[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "tokenized = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
    "\n",
    "# 5. DataLoader 구성\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "dataloader    = DataLoader(\n",
    "    tokenized,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# 6. 학습 준비 (기본은 GPU, 없으면 CPU)\n",
    "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 7. 학습 루프\n",
    "model.train()\n",
    "print(\"🚀 Training start\")\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    for step, batch in enumerate(loop):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % 5 == 0:\n",
    "            loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "print(\"✅ Training complete\")\n",
    "\n",
    "# 8. SafeTensors로 저장\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.save_pretrained(save_dir, safe_serialization=True)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"✅ SafeTensors 모델이 '{save_dir}'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "### 추후 학습 완료 된 model 을 가져올 때는 다음과 같이 진행하면 됨. \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "save_dir = \"./distilbart_cnn_safetensors\"  # 학습 후 저장했던 경로\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(save_dir)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  # GPU:0, 없으면 CPU:-1\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example article : 트럼프 관세 정책\n",
    "article = \"\"\"\n",
    "US President Donald Trump has announced a series of tariffs, arguing they will boost American manufacturing and protect jobs.\n",
    "But the import taxes have thrown the world economy into chaos and many have argued that they will make products more expensive for US consumers.\n",
    "The US and China have now agreed to slash tariffs they had imposed on each other, for 90 days.\n",
    "The UK and US have also announced a deal on tariffs, and other countries are hoping to reach an agreement with the White House.\n",
    "\n",
    "What are tariffs and how do they work?\n",
    "Tariffs are taxes charged on goods bought from other countries.\n",
    "Typically, they are a percentage of a product's value.\n",
    "A10% tariff means a $10 product would have a $1 tax on top - taking the total cost to $11 (£8.35).\n",
    "Companies that bring foreign goods into the US have to pay the tax to the government.\n",
    "They may pass some or all of the extra cost on to customers. Firms may also decide to import fewer goods.\n",
    "\n",
    "Why is Trump using tariffs?\n",
    "Trump says tariffs will encourage US consumers to buy more American-made goods, increase the amount of tax raised and lead to huge levels of investment.\n",
    "He wants to reduce the gap between the value of goods the US buys from other countries and those it sells to them. He argues that America has been taken advantage of by \"cheaters\" and \"pillaged\" by foreigners.\n",
    "The US president has made other demands alongside tariffs.\n",
    "When he announced the first tariffs of his current term against China, Mexico and Canada, he said he wanted them to do more to stop migrants and illegal drugs reaching the US.\n",
    "\"\"\"\n",
    "summary = summarizer(\n",
    "    article,\n",
    "    max_length=60,    # 생성될 요약문의 최대 토큰 수\n",
    "    min_length=20,    # 생성될 요약문의 최소 토큰 수\n",
    "    do_sample=False   # 빔 서치(beam search) 사용\n",
    ")[0][\"summary_text\"]\n",
    "\n",
    "print(\"── 원문 ───────────────────────────────────────────\")\n",
    "print(article.strip(), \"\\n\")\n",
    "print(\"── 요약 ───────────────────────────────────────────\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
