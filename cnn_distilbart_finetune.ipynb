{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file must be run on Colab with T4 GPU\n",
    "Dataset : CNN Daily/Mail 3.0.0\n",
    "\n",
    "Model : DistilBart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade fsspec datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „ ì„¤ì¹˜:\n",
    "# pip install transformers datasets safetensors torch tqdm\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# 1. ì„¤ì •\n",
    "model_name  = \"sshleifer/distilbart-cnn-6-6\"\n",
    "cache_dir   = \"./hf_cache\"                   # ë°ì´í„°ì…‹Â·ëª¨ë¸ ìºì‹œ\n",
    "save_dir    = \"./distilbart_cnn_safetensors\" # ìµœì¢… ì €ì¥ ê²½ë¡œ\n",
    "batch_size  = 2                              # ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •\n",
    "num_epochs  = 1\n",
    "max_samples = 2048                           # ì „ì²´ ìƒ˜í”Œ ì¤‘ ì‚¬ìš©í•  ê°œìˆ˜\n",
    "\n",
    "# 2. í† í¬ë‚˜ì´ì €Â·ëª¨ë¸ ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ë¡œë“œ ë° ìƒ˜í”Œ ì„ íƒ\n",
    "raw_ds  = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\", cache_dir=cache_dir)\n",
    "dataset = raw_ds.select(range(max_samples))\n",
    "\n",
    "# 4. ì „ì²˜ë¦¬ í•¨ìˆ˜: encoder-decoder êµ¬ì¡°ì´ë¯€ë¡œ \"summarize:\" í”„ë¡¬í”„íŠ¸ ë¶ˆí•„ìš”\n",
    "def preprocess(ex):\n",
    "    enc = tokenizer(\n",
    "        ex[\"article\"],\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    lbl = tokenizer(\n",
    "        ex[\"highlights\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\":      enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"],\n",
    "        \"labels\":         lbl[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "tokenized = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
    "\n",
    "# 5. DataLoader êµ¬ì„±\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "dataloader    = DataLoader(\n",
    "    tokenized,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# 6. í•™ìŠµ ì¤€ë¹„ (ê¸°ë³¸ì€ GPU, ì—†ìœ¼ë©´ CPU)\n",
    "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 7. í•™ìŠµ ë£¨í”„\n",
    "model.train()\n",
    "print(\"ğŸš€ Training start\")\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    for step, batch in enumerate(loop):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % 5 == 0:\n",
    "            loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "print(\"âœ… Training complete\")\n",
    "\n",
    "# 8. SafeTensorsë¡œ ì €ì¥\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.save_pretrained(save_dir, safe_serialization=True)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"âœ… SafeTensors ëª¨ë¸ì´ '{save_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "### ì¶”í›„ í•™ìŠµ ì™„ë£Œ ëœ model ì„ ê°€ì ¸ì˜¬ ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ë©´ ë¨. \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "save_dir = \"./distilbart_cnn_safetensors\"  # í•™ìŠµ í›„ ì €ì¥í–ˆë˜ ê²½ë¡œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(save_dir)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  # GPU:0, ì—†ìœ¼ë©´ CPU:-1\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example article : íŠ¸ëŸ¼í”„ ê´€ì„¸ ì •ì±…\n",
    "article = \"\"\"\n",
    "US President Donald Trump has announced a series of tariffs, arguing they will boost American manufacturing and protect jobs.\n",
    "But the import taxes have thrown the world economy into chaos and many have argued that they will make products more expensive for US consumers.\n",
    "The US and China have now agreed to slash tariffs they had imposed on each other, for 90 days.\n",
    "The UK and US have also announced a deal on tariffs, and other countries are hoping to reach an agreement with the White House.\n",
    "\n",
    "What are tariffs and how do they work?\n",
    "Tariffs are taxes charged on goods bought from other countries.\n",
    "Typically, they are a percentage of a product's value.\n",
    "A10% tariff means a $10 product would have a $1 tax on top - taking the total cost to $11 (Â£8.35).\n",
    "Companies that bring foreign goods into the US have to pay the tax to the government.\n",
    "They may pass some or all of the extra cost on to customers. Firms may also decide to import fewer goods.\n",
    "\n",
    "Why is Trump using tariffs?\n",
    "Trump says tariffs will encourage US consumers to buy more American-made goods, increase the amount of tax raised and lead to huge levels of investment.\n",
    "He wants to reduce the gap between the value of goods the US buys from other countries and those it sells to them. He argues that America has been taken advantage of by \"cheaters\" and \"pillaged\" by foreigners.\n",
    "The US president has made other demands alongside tariffs.\n",
    "When he announced the first tariffs of his current term against China, Mexico and Canada, he said he wanted them to do more to stop migrants and illegal drugs reaching the US.\n",
    "\"\"\"\n",
    "summary = summarizer(\n",
    "    article,\n",
    "    max_length=60,    # ìƒì„±ë  ìš”ì•½ë¬¸ì˜ ìµœëŒ€ í† í° ìˆ˜\n",
    "    min_length=20,    # ìƒì„±ë  ìš”ì•½ë¬¸ì˜ ìµœì†Œ í† í° ìˆ˜\n",
    "    do_sample=False   # ë¹” ì„œì¹˜(beam search) ì‚¬ìš©\n",
    ")[0][\"summary_text\"]\n",
    "\n",
    "print(\"â”€â”€ ì›ë¬¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(article.strip(), \"\\n\")\n",
    "print(\"â”€â”€ ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
